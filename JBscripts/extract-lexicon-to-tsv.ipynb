{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "\n",
    "# Main elements in the PropBank frame-files, variables:\n",
    "def extract_target_rolesets(repository_path, output_tsv):\n",
    "    \"\"\"\n",
    "    Extracts rolesets from the PB Lexicon github repository (or whatever repo is desired).\n",
    "\n",
    "    Parameters:\n",
    "    repository_path (str): The path to the directory containing XML files.\n",
    "\n",
    "    Returns:\n",
    "    dict: The dictionary containing extracted roleset information.\n",
    "    \"\"\"\n",
    "    PBLexiconDictionary = {}\n",
    "\n",
    "    # Traverse all files in the specified repository\n",
    "    for root_dir, _, files in os.walk(repository_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".xml\"):  # Process only XML files\n",
    "                file_path = os.path.join(root_dir, file_name)\n",
    "                try:\n",
    "                    tree = ET.parse(file_path)\n",
    "                    root = tree.getroot()\n",
    "\n",
    "                    # Iterate through all predicates in the XML file\n",
    "                    predicates = root.findall(\".//predicate\")\n",
    "                    for predicate in predicates:\n",
    "                        predicate_lemma = predicate.get(\"lemma\")\n",
    "\n",
    "                        # Find all roleset elements within the predicate element\n",
    "                        rolesets = predicate.findall(\".//roleset\")\n",
    "                        for roleset in rolesets:\n",
    "                            roleset_id = roleset.get(\"id\")\n",
    "                            roleset_name = roleset.get(\"name\")\n",
    "\n",
    "                        # initialize dictionary entry for roleset\n",
    "                            if roleset_id not in PBLexiconDictionary:\n",
    "                                PBLexiconDictionary[roleset_id] = {\n",
    "                                    \"definition\": roleset_name,             #DONE\n",
    "                                    \"parent_predicate\": predicate_lemma,    #DONE\n",
    "                                    \"source_file_name\": file_name,          #DONE\n",
    "                                    \"aliases\": {},                          #DONE\n",
    "                                    \"argaliases\": {},                       #DONE\n",
    "                                    \"roles\": {},                            #DONE\n",
    "                                    \"MWE_descriptions\": {},                 #DONE\n",
    "                                #    \"MCP_descriptions\": {},\n",
    "                                    \"entailments\": {},                      #DONE\n",
    "                                    \"usagenotes\": {},                       #DONE\n",
    "                                    \"lexlinks\": [],                         #DONE\n",
    "                                    \"examples\": {},\n",
    "                                    \"notes\": []                             #DONE\n",
    "                                }\n",
    "                            else:\n",
    "                                print(f\"{roleset_id} has duplicate in lexicon.\")\n",
    "\n",
    "\n",
    "                        # Get all aliases of the roleset\n",
    "                            for alias in roleset.findall(\".//alias\"):\n",
    "                                alias_name = f\"{alias.text}-{alias.get('pos', 'unknown')}\"\n",
    "                                if alias_name not in PBLexiconDictionary[roleset_id][\"aliases\"]:\n",
    "                                    PBLexiconDictionary[roleset_id][\"aliases\"][alias_name] = {\n",
    "                                        \"alias_pos\": alias.get(\"pos\"),\n",
    "                                        \"alias_lemma\": alias.text\n",
    "                                    }\n",
    "                                else: \n",
    "                                    print(f\"{roleset_id} alias {alias_name} has duplicate.\")\n",
    "\n",
    "                        \n",
    "                        # Get all argaliases of the roleset\n",
    "                            for argalias in roleset.findall(\".//argalias\"):\n",
    "                                argalias_name = f\"{argalias.text}-{argalias.get('pos', 'unknown')}\"\n",
    "                                if argalias_name not in PBLexiconDictionary[roleset_id][\"argaliases\"]:\n",
    "                                    PBLexiconDictionary[roleset_id][\"argaliases\"][argalias_name] = {\n",
    "                                        \"argalias_pos\": argalias.get(\"pos\"),\n",
    "                                        \"argalias_lemma\": argalias.text,\n",
    "                                        \"argalias_arg\": argalias.get(\"arg\")\n",
    "                                    }\n",
    "                                else: \n",
    "                                    print(f\"{roleset_id} argalias {argalias_name} has duplicate.\")\n",
    "\n",
    "\n",
    "                        # Get all roles of the roleset\n",
    "                            for role in roleset.findall(\".//role\"):\n",
    "                                role_ID = \"ARG\" + role.get(\"n\", \"\")\n",
    "                                \n",
    "                                if role_ID not in PBLexiconDictionary[roleset_id][\"roles\"]:\n",
    "                                    PBLexiconDictionary[roleset_id][\"roles\"][role_ID] = {\n",
    "                                        \"function_tag\": role.get(\"f\"),\n",
    "                                        \"role_def\": role.get(\"descr\"),\n",
    "                                        \"rolelinks\": []\n",
    "                                    }\n",
    "                                else: \n",
    "                                    print(f\"{roleset_id} role {role_ID} has duplicate.\")\n",
    "\n",
    "                                #rolelinks\n",
    "                                for rolelink in role.findall(\".//rolelink\"):\n",
    "                                    PBLexiconDictionary[roleset_id][\"roles\"][role_ID][\"rolelinks\"].append({\n",
    "                                        \"class\": rolelink.get(\"class\"), \n",
    "                                        \"resource\": rolelink.get(\"resource\"), \n",
    "                                        \"version\": rolelink.get(\"version\"), \n",
    "                                        \"role\": rolelink.text\n",
    "                                    })\n",
    "\n",
    "                        # Get all MWE descriptions for aliases (not connected to alias entry currently)\n",
    "                            for MWE in roleset.findall(\".//mwp-descriptions\"):\n",
    "                                MWE_id = f\"{MWE.get('id')}-{MWE.get('pos')}\"\n",
    "\n",
    "                                if MWE_id not in PBLexiconDictionary[roleset_id][\"MWE_descriptions\"]:\n",
    "                                    PBLexiconDictionary[roleset_id][\"MWE_descriptions\"][MWE_id] = {\n",
    "                                        \"literal\": MWE.findtext(\".//source\", \"UNKNOWN\"),\n",
    "                                        \"figurative\": MWE.findtext(\".//target\", \"UNKNOWN\"),\n",
    "                                        \"slots\": None,  \n",
    "                                        \"tokens\": [] \n",
    "                                    }\n",
    "                                else:\n",
    "                                    print(f\"{roleset_id} MWE {MWE_id} has a duplicate.\")\n",
    "\n",
    "                                for desc in MWE.findall(\".//syntaxdesc\"):                                    \n",
    "                                    PBLexiconDictionary[roleset_id][\"MWE_descriptions\"][MWE_id][\"slots\"] = desc.get('slots', 'UNKNOWN')\n",
    "\n",
    "                                    for token in desc.findall(\".//token\"): \n",
    "                                        PBLexiconDictionary[roleset_id][\"MWE_descriptions\"][MWE_id][\"tokens\"].append({\n",
    "                                            \"token\": token.text or \"UNKNOWN\",\n",
    "                                            \"arg\": token.get('arg', 'UNKNOWN'),\n",
    "                                            \"dep\": token.get('dep', 'UNKNOWN'),\n",
    "                                            \"head\": token.get('head', 'UNKNOWN'),\n",
    "                                            \"pos\": token.get('pos', 'UNKNOWN'),\n",
    "                                            \"slot\": token.get('slot', 'UNKNOWN')\n",
    "                                        })\n",
    "\n",
    "\n",
    "                        # Get all entailments (hobbsian spatial entailments) for the roleset\n",
    "                            for entailment in roleset.findall(\".//hobbsian\"):\n",
    "                                PBLexiconDictionary[roleset_id]['entailments'] = {\n",
    "                                    entailment.text\n",
    "                                }\n",
    "\n",
    "\n",
    "                    #TODO (I don't believe there are any of these yet, but do once I start adding them.)\n",
    "                        # Get all MCP descriptions for aliases (not connected to alias entry currently)\n",
    "                        #    MCPs = roleset.findall(\".//mcp-descriptions\")\n",
    "                        #    for MCP in MCPs:\n",
    "                        #        MCP_id = MCP.get(\"id\")\n",
    "\n",
    "                        #        if MCP_id not in PBLexiconDictionary[roleset_id][\"MCP_descriptions\"]:\n",
    "                        #            PBLexiconDictionary[roleset_id][\"MCP_descriptions\"][MCP_id] = {\n",
    "                        #                \"MCP_morphosyntaxdesc\": {\n",
    "                        #                    \"slots\": \"\",\n",
    "                        #                    \"morphs\": {}\n",
    "                        #                },\n",
    "                        #            }\n",
    "                                \n",
    "                                    # token/slot syntax descriptions\n",
    "                        #            morphosyntaxdescs = MCP.findall(\".//syntaxdesc\")\n",
    "                        #            morphosyntax_slots = morphosyntaxdescs.get(\"slots\")\n",
    "                                    \n",
    "                        #            PBLexiconDictionary[roleset_id][\"MCP_descriptions\"][MCP_id][\"slots\"] = morphosyntax_slots\n",
    "\n",
    "                        #            for morphosyntaxdesc in morphosyntaxdescs:\n",
    "                        #                morphs = morphosyntaxdesc.findall(\".//morph\")\n",
    "                        #                for morph in morphs:\n",
    "                        #                    morph_arg = morph.get(\"arg\")\n",
    "                        #                    morph_dep = morph.get(\"dep\")\n",
    "                        #                    morph_head = morph.get(\"head\")\n",
    "                        #                    morph_pos = morph.get(\"pos\")\n",
    "                        #                    morph_slot = morph.get(\"slot\")\n",
    "                        #                    morph_value = morph.text\n",
    "\n",
    "                        #                    PBLexiconDictionary[roleset_id][\"MCP_descriptions\"][MCP_id][\"morphs\"].append({\n",
    "                        #                        \"morph_arg\": morph_arg,\n",
    "                        #                        \"morph_dep\": morph_dep,\n",
    "                        #                        \"morph_head\": morph_head,\n",
    "                        #                        \"morph_pos\": morph_pos,\n",
    "                        #                        \"morph_slot\": morph_slot,\n",
    "                        #                        \"morph_value\": morph_value\n",
    "                        #                    })\n",
    "                                \n",
    "                                    # literal graphs\n",
    "                        #            sources = MCP.findall(\".//source\")\n",
    "                        #            for source in sources:\n",
    "                        #                mcp_literal = source.text\n",
    "\n",
    "                        #                PBLexiconDictionary[roleset_id][\"MCP_descriptions\"][MCP_id][\"MCP_literal_meaning\"] = mcp_literal\n",
    "\n",
    "                                    # figurative graphs\n",
    "                        #            targets = MCP.findall(\".//target\")\n",
    "                        #            for target in targets:\n",
    "                        #                mcp_figurative = target.text\n",
    "\n",
    "                        #                PBLexiconDictionary[roleset_id][\"MCP_descriptions\"][MCP_id][\"MCP_figurative_meaning\"] = mcp_figurative\n",
    "                            \n",
    "                        #        else: \n",
    "                        #            print(f\"{roleset_id} mcp description {MCP_id} has duplicate entry.\")\n",
    "                            \n",
    "\n",
    "                        # Get all usage notes\n",
    "                            for usage in roleset.findall(\".//usage\"):\n",
    "                                usagenote_id = f\"{usage.get('resource')}-{usage.get('version')}\"\n",
    "                                if usagenote_id not in PBLexiconDictionary[roleset_id][\"usagenotes\"]:\n",
    "                                    PBLexiconDictionary[roleset_id][\"usagenotes\"][usagenote_id] = usage.get(\"inuse\")\n",
    "                                else: \n",
    "                                    print(f\"{roleset_id} usagenote {usagenote_id} has duplicate.\")\n",
    "\n",
    "  \n",
    "                        # Get all lexlinks\n",
    "                            for lexlink in roleset.findall(\".//lexlink\"):\n",
    "                                PBLexiconDictionary[roleset_id][\"lexlinks\"].append({\n",
    "                                    \"resource\": lexlink.get(\"resource\") or \"-\", \n",
    "                                    \"version\": lexlink.get(\"version\") or \"-\", \n",
    "                                    \"class\": lexlink.get(\"class\") or \"-\", \n",
    "                                    \"confidence\": lexlink.get(\"confidence\") or \"-\", \n",
    "                                    \"src\": lexlink.get(\"src\") or \"-\"\n",
    "                                })\n",
    "\n",
    "                        # Get all examples\n",
    "                            for example in roleset.findall(\".//example\"):\n",
    "                                example_id = f\"example_{len(PBLexiconDictionary[roleset_id]['examples']) + 1}\"\n",
    "                                PBLexiconDictionary[roleset_id][\"examples\"][example_id] = {\n",
    "                                    \"example_name\": example.get(\"name\"),\n",
    "                                    \"example_src\": example.get(\"src\"),\n",
    "                                    \"sentence\": example.findtext(\".//text\", \"\"),\n",
    "                                    \"PB_annot\": {\"relations\": [], \"arguments\": []},\n",
    "                                    \"AMR_annot\": [],\n",
    "                                    \"UMR_annot\": []\n",
    "                                }\n",
    "                                \n",
    "\n",
    "                            # Get all PropBank annotations for example\n",
    "                                for rel in example.findall(\".//rel\"):\n",
    "                                    PBLexiconDictionary[roleset_id][\"examples\"][example_id][\"PB_annot\"][\"relations\"].append({\n",
    "                                        \"relation\": rel.text.strip() if rel.text else \"UNKNOWN\",\n",
    "                                        \"relloc\": rel.get(\"relloc\", \"UNKNOWN\")\n",
    "                                    })\n",
    "\n",
    "                                for arg in example.findall(\".//arg\"):\n",
    "                                    PBLexiconDictionary[roleset_id][\"examples\"][example_id][\"PB_annot\"][\"arguments\"].append({\n",
    "                                        \"text\": arg.text.strip() if arg.text else \"UNKNOWN\",\n",
    "                                        \"arg\": arg.get(\"type\", \"UNKNOWN\"),\n",
    "                                        \"start\": arg.get(\"start\", \"UNKNOWN\"),\n",
    "                                        \"end\": arg.get(\"end\", \"UNKNOWN\")\n",
    "                                    })\n",
    "\n",
    "\n",
    "                            # Get all AMRs for the example\n",
    "                                for AMR in roleset.findall(\".//amr\"):\n",
    "                                    AMR_id = f\"AMR-{AMR.get('version')}\"\n",
    "                                    PBLexiconDictionary[roleset_id][\"examples\"][example_id][\"AMR_annot\"].append({\n",
    "                                        'amr_id': AMR_id,\n",
    "                                        'graph': AMR.text.strip() if AMR.text else \"UNKNOWN\"\n",
    "                                    })\n",
    "\n",
    "                            # Get all UMRs of the example\n",
    "                                for UMR in roleset.findall(\".//umr\"):\n",
    "                                    UMR_id = f\"UMR-{UMR.get('version')}\"\n",
    "                                    PBLexiconDictionary[roleset_id][\"examples\"][example_id][\"UMR_annot\"].append({\n",
    "                                        'umr_id': UMR_id,\n",
    "                                        'graph': UMR.text.strip() if UMR.text else \"UNKNOWN\"\n",
    "                                    })\n",
    "\n",
    "\n",
    "                        # Get all notes\n",
    "                            for note in roleset.findall(\".//note\"):\n",
    "                                if note.text:\n",
    "                                    PBLexiconDictionary[roleset_id][\"notes\"].append(note.text.strip())\n",
    "                            \n",
    "            # Handle XML parsing errors            \n",
    "                except ET.ParseError as e:\n",
    "                    print(f\"Error parsing file {file_path}: {e}\")  \n",
    "\n",
    "        \n",
    "    # Writing to TSV file\n",
    "    with open(output_tsv, \"w\", newline=\"\", encoding=\"utf-8\") as tsvfile:\n",
    "        writer = csv.writer(tsvfile, delimiter=\"\\t\")\n",
    "        writer.writerow([\"Source File\", \"Parent Predicate\", \"Roleset ID\", \"Definition\", \"Aliases\", \"ARG-Aliases\", \"Roles\", \"Usage Notes\", \"Lexlinks\", \"MWEs\", \"Examples\", \"Notes\", \"Entailments\"])     #, \"Roles\", \"Lexlinks\", \"Examples\", \"Notes\"\n",
    "\n",
    "        for roleset_id, data in PBLexiconDictionary.items():\n",
    "\n",
    "            mwe_output = '\"' + \"\\n\".join([\n",
    "                f\"MWE: {mwe_id} (slots= {mwe_data.get('slots', 'UNKNOWN')}) \" +\n",
    "                (\"\\n\" + \"\\n\".join([\n",
    "                    f\"  TOKEN: {token['token']} (slot={token['slot']}, arg={token['arg']}, dep={token['dep']}, head={token['head']}, pos={token['pos']})\"\n",
    "                        for token in mwe_data[\"tokens\"]\n",
    "                        ]) if mwe_data[\"tokens\"] else \"\") +\n",
    "                f\"\\nLiteral mapping: \\n{mwe_data.get('literal', 'UNKNOWN')}\" +\n",
    "                f\"\\nFigurative mapping: {mwe_data.get('figurative', 'UNKNOWN')}\"  # FIXED: Correct key name\n",
    "                for mwe_id, mwe_data in data[\"MWE_descriptions\"].items()\n",
    "            ]) + '\"'\n",
    "                \n",
    "            examples_output = '\"' + \"\\n\".join([\n",
    "                f\"{example_id} (src= {example_data.get('example_src', 'UNKNOWN')}): \\n  {example_data.get('sentence', 'UNKNOWN')}\" +        # text\n",
    "                (\"\\n\" + \"\\n\".join([f\"    REL: {rel['relation']} (loc={rel['relloc']})\"                                                    # PB annotation\n",
    "                        for rel in example_data[\"PB_annot\"][\"relations\"]]) if example_data[\"PB_annot\"][\"relations\"] else \"\") +\n",
    "                (\"\\n\" + \"\\n\".join([f\"    {arg['arg']}: {arg['text']} (start={arg['start']}, end={arg['end']})\" \n",
    "                        for arg in example_data[\"PB_annot\"][\"arguments\"]]) if example_data[\"PB_annot\"][\"arguments\"] else \"\") +\n",
    "                (\"\\n\" + \"\\n\".join([f\"  {amr['amr_id']}: \\n        {amr['graph']}\"                                                          # AMR annotation\n",
    "                        for amr in example_data[\"AMR_annot\"]]) if example_data[\"AMR_annot\"] else \"\") +\n",
    "                (\"\\n\" + \"\\n\".join([f\"  {umr['umr_id']}: \\n        {umr['graph']}\"                                                          # UMR annotation\n",
    "                        for umr in example_data[\"UMR_annot\"]]) if example_data[\"UMR_annot\"] else \"\")\n",
    "                for example_id, example_data in data[\"examples\"].items()\n",
    "            ]) + '\"'\n",
    "\n",
    "            argalias_output = '\"' + \"\\n\".join([\n",
    "                f\"{argalias_name}: ARG{argalias_data['argalias_arg']}\"\n",
    "                for argalias_name, argalias_data in data[\"argaliases\"].items()\n",
    "            ]) + '\"'\n",
    "\n",
    "            roles_output = '\"' + \"\\n\".join([\n",
    "                f\"{role_id}-{role_data['function_tag']}: {role_data['role_def']}\" +\n",
    "                (\"\\n\" + \"\\n\".join([f\"    {link['role']}, {link['class']}, {link['resource']}-{link['version']}\" \n",
    "                        for link in role_data[\"rolelinks\"]]) if role_data[\"rolelinks\"] else \"\")\n",
    "                for role_id, role_data in data[\"roles\"].items()\n",
    "            ]) + '\"'\n",
    "\n",
    "            usagenotes_output = '\"' + \"\\n\".join([\n",
    "                f\"{usagenote_id or 'NONE'}: {inuse or 'NONE'}\" for usagenote_id, inuse in data[\"usagenotes\"].items() \n",
    "            ]) + '\"'\n",
    "\n",
    "            lexlinks_output = '\"' + \"\\n\".join([\n",
    "                f\"{link['resource']}-{link['version']}: {link['class']} (Confidence: {link['confidence']}, Source: {link['src']})\"\n",
    "                for link in data[\"lexlinks\"]\n",
    "            ]) + '\"'\n",
    "\n",
    "\n",
    "            writer.writerow([\n",
    "                data[\"source_file_name\"],\n",
    "                data[\"parent_predicate\"],\n",
    "                roleset_id,\n",
    "                data[\"definition\"],\n",
    "                '\"' + \"\\n\".join(data[\"aliases\"].keys()) + '\"',\n",
    "                argalias_output,\n",
    "                roles_output,\n",
    "                usagenotes_output,\n",
    "                lexlinks_output,\n",
    "                mwe_output,\n",
    "                examples_output,\n",
    "                '\"' + \"\\n\".join(data[\"notes\"]) + '\"',\n",
    "                data[\"entailments\"]\n",
    "            ])\n",
    "\n",
    "    return PBLexiconDictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up.11 has duplicate in lexicon.\n",
      "up.11 role ARG1 has duplicate.\n",
      "up.11 role ARG2 has duplicate.\n",
      "up.11 usagenote PropBank-1.0 has duplicate.\n",
      "up.11 usagenote PropBank-2.1.5 has duplicate.\n",
      "up.11 usagenote PropBank-3.1 has duplicate.\n",
      "up.11 usagenote PropBank-3.4 has duplicate.\n",
      "up.11 usagenote AMR-2019 has duplicate.\n",
      "up.11 usagenote PropBank-Flickr 1.0 has duplicate.\n",
      "up.11 usagenote AMR-Spatial 1.0 has duplicate.\n",
      "up.11 usagenote AMR-THYME 1.0 has duplicate.\n",
      "up.11 usagenote PropBank-3.5 has duplicate.\n",
      "up.11 usagenote AMR-iSAT 1.0 has duplicate.\n"
     ]
    }
   ],
   "source": [
    "repository_path = \"C:/Users/littl/OneDrive/Documents/GitHub/PROPBANK-FRAMES/frames\"\n",
    "output_tsv = \"output_PBdict_friday.tsv\"\n",
    "data = extract_target_rolesets(repository_path, output_tsv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
